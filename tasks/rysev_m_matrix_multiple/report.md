Task Перемножение матриц по ленточной схеме (разбиение первой матрицы)

Student: Рысев Михаил, group 3823Б1ФИ2
Technology: SEQ | MPI
Variant: 13
1. Introduction

Умножение матриц является одной из базовых операций линейной алгебры, широко применяемой в научных вычислениях, машинном обучении, компьютерной графике и других областях. При работе с матрицами большого размера последовательное умножение становится узким местом производительности. Параллельная реализация с использованием MPI позволяет значительно ускорить вычисления за счет распределения нагрузки между несколькими процессами. В данной работе реализовано перемножение квадратных матриц по ленточной схеме с разбиением только первой матрицы.
2. Problem Statement

Для двух квадратных матриц A и B размера n×n, заданных в виде одномерных массивов по строкам, необходимо вычислить матрицу C = A × B, где элемент C[i][j] вычисляется по формуле:

C[i][j] = Σ(k=1 до n) A[i][k] * B[k][j]

Входные данные: std::tuple<std::vector<int>, std::vector<int>, int> - две матрицы (в виде векторов) и их размер
Выходные данные: std::vector<int> - результирующая матрица в виде вектора по строкам

Ограничения:

    Матрицы квадратные, размер n > 0

    Матрицы представлены в виде одномерных векторов длины n²

    Элементы матриц - целые числа

3. Baseline Algorithm (Sequential)

Последовательный алгоритм реализует классическое умножение матриц по определению: тройной вложенный цикл.

Сложность алгоритма: O(n³), где n - размер матрицы.
4. Parallelization Scheme

В данной работе используется ленточная схема с горизонтальным разбиением только первой матрицы. Вторая матрица передается всем процессам полностью.
Распределение данных

    Матрица A разбивается горизонтально на полосы (наборы строк)

    Количество строк на процесс определяется по формуле: base_rows = size / num_procs, остаток распределяется между первыми процессами

    Матрица B полностью рассылается всем процессам


Каждый процесс:

    Получает свою полосу матрицы A (горизонтальные полосы)
    Получает полную копию матрицы B
    Вычисляет свою полосу результирующей матрицы C
    Отправляет результаты на процесс 0

Роли процессов

    Процесс 0: распределяет данные (полосы A, копии B), собирает результаты, формирует итоговую матрицу
    Все процессы: выполняют умножение своей полосы A на B

Коммуникации

    Bcast для рассылки размера матрицы
    Bcast для рассылки матрицы B всем процессам
    Scatterv для распределения полос матрицы A
    Gatherv для сбора полос результирующей матрицы C
    Barrier для синхронизации

5. Implementation Details
Структура проекта

rysev_m_matrix_multiple/
├── common/
│ └── common.hpp // Общие типы данных
├── seq/
│ ├── ops_seq.hpp // SEQ заголовок
│ └── ops_seq.cpp // SEQ реализация
├── mpi/
│ ├── ops_mpi.hpp // MPI заголовок
│ └── ops_mpi.cpp // MPI реализация
└── tests/
├── functional/ // Функциональные тесты
└── performance/ // Тесты производительности
Ключевые классы

    RysevMMatrMulSEQ - последовательная реализация
    RysevMMatrMulMPI - параллельная MPI реализация


Обработка особых случаев

    Неравномерное распределение строк при неделящемся размере матрицы
    Процессы без данных (если процессов больше чем строк) - корректная обработка
    Пустые матрицы - валидация на входе

6. Experimental Setup
Hardware/OS

    Процессор: AMD Ryzen 5 3500U, 4 ядра, 8 потоков
    Тактовая частота: 2.10 GHz (базовая), до 3.7 GHz (Boost)
    Оперативная память: 8 GB DDR4
    Накопитель: 477 GB SSD
    Операционная система: Windows 10 Home 22H2 (сборка 19045.6456)

Software

    Компилятор: g++ (GCC) 14.2.0
    MPI реализация: OpenMPI (в Docker-контейнере)
    Сборка: Release (оптимизация -O2)
    Тестовые данные: Квадратные матрицы размером 1000×1000 (1e6 элементов)

Environment

    Запуск в Docker-контейнере для воспроизводимости результатов
    Количество процессов: 2, 4
    Количество измерений: 5 запусков для каждого режима (усреднение)

7. Results and Discussion
7.1 Correctness

Корректность реализации проверена с помощью набора функциональных тестов:

    Случайные матрицы различных размеров
    Крайние случаи (минимальный размер 1×1)
    Проверка на единичных матрицах
    Сравнение результатов SEQ и MPI версий

7.2 Performance

SEQ версия алгоритма выполняется за 0,0005690098 с., а MPI версия за 0,0003310212 с. Доля ускорения составляет 1,71

8. Conclusions

В ходе работы успешно реализована параллельная MPI версия алгоритма умножения матриц с использованием ленточной схемы и разбиением только первой матрицы.

Основные достижения:

    Разработана масштабируемая схема с горизонтальным разбиением матрицы A
    Высокая эффективность (86%) подтверждает правильность выбранного подхода

Наблюдения:

    Алгоритм хорошо масштабируется благодаря преобладанию вычислений над коммуникациями
    Основные потери эффективности связаны с рассылкой матрицы B и сбором результатов

Перспективы улучшения:

    Использование неблокирующих операций для перекрытия вычислений и коммуникаций
    Оптимизация распределения при неравномерном делении
    Возможное использование двумерной декомпозиции для очень больших матриц

9. References

    Лекции и практики курса "Параллельное программирование для кластерных систем"

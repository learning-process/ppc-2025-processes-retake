# Нахождение минимальных значений по столбцам матрицы

- Student: Солонин Владислав Викторович, group 3823Б1ПР1
- Technology: SEQ | MPI
- Variant: 1

## 1. Introduction

Нахождение минимальных значений по столбцам матрицы — задача, часто встречающаяся в численных методах и анализе данных. Цель работы — реализация и сравнение последовательного (SEQ) и параллельного (MPI) алгоритмов, оценка эффективности распараллеливания.

## 2. Problem Statement

Для квадратной матрицы размером `n×n` найти минимальный элемент в каждом столбце и вернуть вектор минимумов длины `n`.

**Вход:** целое число `n > 0` (размер матрицы).
**Выход:** вектор `std::vector<int>` длины `n`, где элемент `j` — минимум `j`-го столбца.

Матрица не хранится в памяти — элементы генерируются на лету через детерминированный генератор Xorshift по индексам `(i, j)`.

## 3. Baseline Algorithm (Sequential)

Для каждого столбца `j` инициализируется минимум из элемента `(0, j)`, затем цикл по строкам `i = 1..n-1` обновляет минимум через `std::min`. Результат добавляется в выходной вектор.

Временная сложность: `O(n²)`. Память: `O(n)`.

## 4. Parallelization Scheme

Строки матрицы равномерно распределяются между MPI-процессами. Каждый процесс вычисляет локальные минимумы по столбцам для своих строк. Затем выполняется `MPI_Reduce` с операцией `MPI_MIN` для получения глобальных минимумов, после чего `MPI_Bcast` рассылает результат всем процессам.

```
rank 0: строки [0, n/p)        → local_min_0
rank 1: строки [n/p, 2n/p)     → local_min_1
...
MPI_Reduce(MPI_MIN) → global_min
MPI_Bcast           → все процессы получают результат
```

Остаток строк (`n % size`) распределяется по одной на первые процессы.

## 5. Implementation Details

- `common/include/common.hpp` — типы `InType = int`, `OutType = std::vector<int>`
- `seq/` — последовательная реализация
- `mpi/` — параллельная реализация через MPI
- `tests/functional/` — функциональные тесты
- `tests/performance/` — тесты производительности

Функция `Generate(i, j)` детерминированно вычисляет элемент матрицы через Xorshift, что позволяет не хранить матрицу целиком.

## 6. Experimental Setup

- **Hardware:** AMD Ryzen 7, 8 cores, 16 GB RAM
- **OS:** Ubuntu 24.04
- **Compiler:** GCC 14, Release
- **MPI:** OpenMPI
- **PPC_NUM_PROC:** 1, 2, 4
- **Data:** матрица 10000×10000, генерируется детерминированно

## 7. Results and Discussion

### 7.1 Correctness

SEQ и MPI реализации сравниваются поэлементно на матрицах от 1×1 до 512×512. Результаты совпадают во всех тестах. Проверены граничные случаи: `n=1`, `n=0` (отклонение валидацией), неравномерное деление строк.

### 7.2 Performance

| Mode | Processes | Time, s | Speedup | Efficiency |
|------|-----------|---------|---------|------------|
| seq  | 1         | 0.284   | 1.00    | N/A        |
| mpi  | 2         | 0.135   | 2.10    | 105%       |
| mpi  | 4         | 0.078   | 3.64    | 91%        |

## 8. Conclusions

MPI-реализация показала хорошее ускорение: ~2.1x на 2 процессах и ~3.6x на 4. Алгоритм эффективно масштабируется благодаря независимости вычислений по строкам. Единственная коммуникация — `MPI_Reduce` + `MPI_Bcast` — незначительна по сравнению с объёмом вычислений при больших `n`.

## 9. References

1. Гергель В.П. и др. Параллельные вычисления. Технологии и численные методы. — Нижний Новгород, 2013.
2. MPI Forum. MPI: A Message-Passing Interface Standard. https://www.mpi-forum.org/

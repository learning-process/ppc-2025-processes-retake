# Максимальное значение в столбцах матрицы

- Student: Лучников Евгений, group 3823Б1ПР5
- Technology: SEQ | MPI
- Variant: 21

## 1. Introduction

Задача поиска максимального значения в каждом столбце матрицы является важной операцией в обработке данных, машинном обучении и анализе изображений. Параллельная реализация на основе MPI позволяет эффективно распределить вычисления между процессами, что особенно актуально для матриц большого размера.

## 2. Problem Statement

**Формальная постановка задачи:** Для заданной матрицы A размером M×N найти максимальный элемент в каждом столбце и сформировать вектор результатов длины N.

**Входные данные:** Двумерный вектор целых чисел (`std::vector<std::vector<int>>`)

**Выходные данные:** Вектор целых чисел длины N, где каждый элемент - максимальное значение в соответствующем столбце

**Ограничения:**
- Матрица не пустая
- Все строки матрицы имеют одинаковую длину
- Элементы матрицы - целые числа

## 3. Baseline Algorithm (Sequential)

В последовательной версии создается вектор результатов, инициализированный минимальными значениями (`INT_MIN`). Затем выполняется двойной цикл: внешний по столбцам, внутренний по строкам. Для каждого столбца происходит сравнение текущего максимума со значениями во всех строках с обновлением при необходимости. Временная сложность составляет O(M×N).

## 4. Parallelization Scheme

Матрица преобразуется в одномерный массив и разделяется горизонтально на блоки строк с использованием `MPI_Scatterv`:
- Каждый процесс получает приблизительно равное количество строк
- Неравномерное распределение учитывается через расчет остатка от деления (remainder)
- После вычисления локальных максимумов выполняется глобальная редукция через `MPI_Allreduce` с операцией `MPI_MAX`
- Все процессы синхронизируются через `MPI_Barrier` для обеспечения корректности завершения

## 5. Implementation Details

- **common.hpp** - определение базовых типов: `InType` (матрица), `OutType` (вектор максимумов), `TestType` (параметры тестов)
- **ops_seq.hpp/cpp** - последовательная версия с прямым двойным циклом по строкам и столбцам, хранением копии матрицы
- **ops_mpi.hpp/cpp** - MPI версия с использованием:
  - `MPI_Comm_rank` и `MPI_Comm_size` для определения ранга и общего числа процессов
  - `MPI_Bcast` для рассылки размеров матрицы всем процессам
  - `MPI_Scatterv` для неравномерного распределения строк матрицы
  - `MPI_Allreduce` с операцией `MPI_MAX` для сбора глобальных максимумов
  - `MPI_Barrier` для синхронизации процессов
- **func_tests/main.cpp** - 10 функциональных тестов с различными паттернами матриц (pattern1-pattern10), использующих детерминированные формулы генерации
- **perf_tests/main.cpp** - производительностные тесты на матрице 100×100 элементов

## 6. Experimental Setup

- Процессор: Intel Core i7-10750H (6 ядер, 12 потоков)
- Память: 16 ГБ RAM
- ОС: Ubuntu 20.04
- Компилятор: g++ (версия 9.4.0), режим сборки Release
- MPI: OpenMPI 4.0.3

## 7. Results and Discussion

### 7.1 Correctness

Корректность работы проверялась на 10 различных тестовых сценариях с матрицами размеров от 3×3 до 10×10:
- **pattern1**: детерминированный псевдослучайный паттерн на основе линейной комбинации индексов
- **pattern2**: возрастающая последовательность по строкам
- **pattern3**: убывающая последовательность
- **pattern4**: константная матрица со значением 42
- **pattern5**: диагональная матрица с максимальными значениями на главной диагонали
- **pattern6**: матрица с отрицательными значениями
- **pattern7**: смешанные положительные и отрицательные значения
- **pattern8**: матрица с одним глобальным максимумом в центре
- **pattern9**: максимумы в последнем столбце
- **pattern10**: максимумы в первом столбце

Все тесты подтверждают полное совпадение результатов MPI и SEQ версий.

### 7.2 Performance

Измерения производительности на матрице 100×100 элементов:

| Mode | Processes | Time, ms | Speedup | Efficiency |
|------|-----------|----------|---------|------------|
| seq  | 1         | 0.98     | 1.00    | N/A        |
| mpi  | 2         | 0.52     | 1.88    | 94.0%      |
| mpi  | 3         | 0.38     | 2.58    | 86.0%      |
| mpi  | 4         | 0.31     | 3.16    | 79.0%      |
| mpi  | 6         | 0.26     | 3.77    | 62.8%      |

**Анализ производительности:**
- Наилучшее ускорение достигается при использовании 6 процессов (в 3.77 раза)
- Эффективность снижается с ростом числа процессов из-за накладных расходов на коммуникацию
- Операции `MPI_Scatterv` и `MPI_Allreduce` вносят дополнительную задержку, особенно заметную при увеличении числа процессов
- Преобразование матрицы в одномерный массив позволяет эффективно использовать коллективные операции MPI

## 8. Conclusions

В результате работы реализованы последовательная и параллельная версии алгоритма поиска максимальных значений в столбцах матрицы. MPI версия эффективно использует распределение данных через `MPI_Scatterv` и глобальную редукцию через `MPI_Allreduce`, демонстрируя ускорение до 3.77 раз на 6 процессах. Разработанные 10 функциональных тестов с различными паттернами данных подтверждают корректность реализации для всех типов входных матриц. Параллельная реализация хорошо масштабируется и может быть использована для обработки матриц больших размеров в многопроцессорных системах.

## 9. References

1. Материалы курса "Параллельное программирование для кластерных систем", ННГУ им. Н.И. Лобачевского
2. MPI: A Message-Passing Interface Standard, Version 4.0
3. Quinn M.J. Parallel Programming in C with MPI and OpenMP, 2003
4. Antoniu, G., et al. "Performance Analysis of MPI Collective Operations", 2005
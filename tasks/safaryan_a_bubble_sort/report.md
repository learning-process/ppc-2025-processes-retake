Сортировка пузырьком (алгоритм чёт-нечётной перестановки)
Студент: Сафарян Григор Ваагнович
Группа: 3823Б1ПР5
Технологии: SEQ | MPI
Вариант: 21

1. Введение

Сортировка данных является одной из базовых операций обработки информации. 
В работе реализован алгоритм пузырьковой сортировки в последовательной (SEQ) 
и параллельной (MPI) версиях.

Параллельная версия основана на алгоритме чёт-нечётной перестановки 
(Odd-Even Transposition Sort), который позволяет распараллелить процесс сортировки 
путём обмена данными между соседними процессами.

2. Постановка задачи

Входные данные:
using InType = std::vector<int>;

Выходные данные:
using OutType = std::vector<int>;

Дан массив из n целых чисел.
Требуется вернуть отсортированный по возрастанию массив.

3. Последовательная реализация (SEQ)

Используется классический алгоритм пузырьковой сортировки.

Идея:
- На каждой итерации сравниваются соседние элементы.
- Если левый элемент больше правого, выполняется обмен.
- После каждой внешней итерации максимальный элемент 
  перемещается в конец массива.

Сложность алгоритма: O(n^2).

4. Параллельная реализация (MPI)

4.1 Общая схема

1. Процесс 0 получает входной массив.
2. Размер массива n рассылается всем процессам через MPI_Bcast.
3. Массив делится на p подмассивов (p — число процессов).
4. Каждый процесс сортирует свой локальный подмассив пузырьковой сортировкой.
5. Выполняется p+1 фаз чёт-нечётных обменов между соседними процессами.
6. Результат собирается через MPI_Allgatherv.

4.2 Распределение данных

Размер локального подмассива:
local_size = n / p + (rank < n % p ? 1 : 0)

Распределение массива выполняется через MPI_Scatterv.

4.3 Локальная сортировка

Каждый процесс выполняет пузырьковую сортировку своего подмассива.

4.4 Чёт-нечётные фазы

Выполняется p+1 шагов:

- На чётной фазе обмениваются пары (0–1), (2–3), ...
- На нечётной фазе обмениваются пары (1–2), (3–4), ...

Процессы используют MPI_Sendrecv для обмена.
После обмена выполняется упорядоченное слияние (merge):

- Левый процесс сохраняет меньшую часть элементов.
- Правый процесс сохраняет большую часть элементов.

Таким образом достигается глобальная упорядоченность массива.

4.5 Сбор результата

После завершения фаз все локальные подмассивы объединяются 
в финальный массив через MPI_Allgatherv.

5. Структура проекта

common.hpp              — типы входных/выходных данных
ops_seq.hpp/.cpp        — последовательная реализация
ops_mpi.hpp/.cpp        — MPI-реализация
functional/main.cpp     — функциональные тесты
performance/main.cpp    — тесты производительности

6. Экспериментальная среда

CPU: Apple M1
RAM: 8 GB
ОС: Ubuntu 24.04 (DevContainer / macOS 26.1)
Компилятор: GCC 13.3.0, C++20, Release
MPI: Open MPI 4.1.6

7. Результаты

7.1 Корректность

Использовались 3 тестовых файла с различными наборами чисел.
Обе реализации (SEQ и MPI) успешно прошли функциональные тесты.

7.2 Производительность

Тест: массив из 20000 элементов (в убывающем порядке).

Mode   Proc   Time (s)   Speedup   Efficiency
seq    1      0.366      1.00      —
mpi    1      0.361      1.01      101%
mpi    2      0.103      3.55      178%
mpi    4      0.037      9.89      247%
mpi    8      0.018      20.33     254%

Наблюдается значительное ускорение при увеличении числа процессов.
Эффективность выше 100% объясняется кэш-эффектами 
и уменьшением размера локальных подмассивов.

8. Заключение

В работе реализована последовательная и параллельная версии 
пузырьковой сортировки.

Параллельная реализация на основе алгоритма чёт-нечётной перестановки 
позволила существенно ускорить выполнение программы 
и продемонстрировала хорошую масштабируемость.
# Вычисление многомерных интегралов методом Монте-Карло

- Student: Царьков Клим Александрович, группа 3823Б1ПР4
- Technology: MPI + SEQ
- Variant: 10

## 1. Введение

Метод Монте-Карло позволяет приближённо вычислять интегралы в пространствах
большой размерности, используя статистическое усреднение случайных выборок.  

Цель работы — реализовать последовательную и MPI-версию алгоритма Монте-Карло
для вычисления интеграла по гиперкубу, проверить корректность и оценить производительность.

## 2. Постановка задачи

Требуется вычислить интеграл:

\[
I = \int_{[0,1]^d} e^{-\|x\|^2} \, dx
\]

где:

- \( d \) — размерность пространства,
- \( x \in [0,1]^d \),
- \( \|x\|^2 = \sum x_i^2 \).

### Входные данные

`InType = {dimension, samples, seed}`

- `dimension` — размерность \( d > 0 \)
- `samples` — количество случайных точек \( N > 0 \)
- `seed` — начальное значение генератора случайных чисел

### Выходные данные

`OutType = double` — оценка интеграла.

## 3. Базовый алгоритм (последовательный)

Используется классическая формула Монте-Карло:

\[
I \approx \frac{1}{N} \sum_{i=1}^{N} f(x_i)
\]

где:

- \( x_i \) — равномерно распределённые точки из \([0,1]^d\),
- \( f(x) = e^{-\|x\|^2} \).

Алгоритм:

1. Генерация \( N \) случайных точек.
2. Вычисление значения функции в каждой точке.
3. Усреднение полученных значений.

Сложность алгоритма:  
\[
O(N \cdot d)
\]

## 4. Схема распараллеливания (MPI)

### Декомпозиция данных

Общее число выборок \( N \) делится между процессами MPI.  
Каждый процесс вычисляет частичную сумму по своему подмножеству точек.

### Обмен данными

- Используется `MPI_Reduce` для суммирования частичных результатов.
- Процесс с рангом 0 выполняет финальное деление на \( N \).

### Роли процессов

- Rank 0 — агрегирует результат.
- Остальные процессы — выполняют локальные вычисления.

Коммуникационные затраты минимальны (одна операция редукции), что обеспечивает хорошую масштабируемость.

## 5. Детали реализации

### Структура проекта

```md
tasks/tsarkov_k_monte_carlo_integration/
  common/include/common.hpp
  seq/include/ops_seq.hpp
  seq/src/ops_seq.cpp
  mpi/include/ops_mpi.hpp
  mpi/src/ops_mpi.cpp
  tests/
  report.md
```

### Особенности

- Генератор случайных чисел инициализируется фиксированным seed.
- Проверяется корректность входных данных.
- Результат должен быть конечным и находиться в диапазоне (0, 1].

Память:  
Используется O(d) на процесс (вектор одной точки).

## 6. Экспериментальная среда

### Аппаратное обеспечение

- CPU: Intel Core i5-1135G7 (4 ядра / 8 потоков)
- RAM: 8 GB
- ОС: Windows 10

### Инструменты

- Компилятор: MSVC (Visual Studio 2022)
- MPI: MS-MPI
- Тип сборки: Release

### Параметры запуска

- 1 процесс (SEQ)
- 2 процесса (MPI)
- 4 процесса (MPI)

### Параметры perf-теста

dimension = 5
samples = 500000
seed = 123

Тестирование выполнялось средствами фреймворка PPC.

## 7. Результаты и обсуждение

### 7.1 Корректность

Корректность проверена с помощью функциональных тестов:

- Несколько значений размерности и количества выборок.
- Проверка диапазона результата (0, 1].
- Тестирование SEQ и MPI режимов.

Все тесты пройдены успешно.

### 7.2 Производительность

#### Pipeline

| Mode | Count | Time, s | Speedup | Efficiency |
|------|-------|---------|---------|------------|
| mpi  | 1     | 0.02434 | 1.00    | 100%       |
| mpi  | 2     | 0.01286 | 1.89    | 94.5%      |

#### Task_run

| Mode | Count | Time, s | Speedup | Efficiency |
|------|-------|---------|---------|------------|
| mpi  | 1     | 0.02655 | 1.00    | 100%       |
| mpi  | 2     | 0.01377 | 1.93    | 96.5%      |

Наблюдается почти линейное ускорение при использовании 2 процессов.  
Эффективность превышает 94%, что свидетельствует о низких накладных расходах на коммуникацию.

## 8. Заключение

В работе реализован метод Монте-Карло для вычисления многомерного интеграла.  

Последовательная и MPI-версии успешно проходят функциональные тесты.  
MPI-реализация демонстрирует хорошую масштабируемость и высокую эффективность распараллеливания.

Метод Монте-Карло показал устойчивость к росту размерности и пригодность для параллельных вычислений.

## 9. Источники

1. Kalos M. H., Whitlock P. A. *Monte Carlo Methods*
2. MPI Standard Documentation — <https://www.mpi-forum.org/docs/>
3. Документация Microsoft MPI — <https://learn.microsoft.com/>
4. Учебные материалы курса PPC (лекции и практики)

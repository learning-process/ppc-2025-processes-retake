# Минимальный элемент вектора

- Студент: Савва Дария Александровна, 3823Б1ФИ1
- Технологии: SEQ | MPI
- Вариант: 4

## 1. Введение

Целью данной работы является реализация алгоритма нахождения минимального элемента вектора.
Алгоритм должен иметь последовательную и параллельную версии.

## 2. Постановка задачи

Дан вектор составленный из N элементов, элементами являются числа. Среди данных элементов
необходимо найти элемент, имеющий минимальное значение.

## 3. Описание линейного алгоритма

Последовательная версия:
осуществляется последовательный проход по всем элементам вектора, на каждом шаге сравнивается
значение текущего элемента с элементом, который является минимальным на данный момент.

## 4. Описание схемы параллельного алгоритма

Пусть имеется K процессов и вектор размера N. Если N кратно K, вектор делится на K равных частей.
Каждая часть обратывается соответсвующим процессом.
Локальная обработка части вектора - это последовательный поиск минимума в данной части вектора.
Если N не кратно K, каждый процесс получает S элементов,
где S - результат целочисленного деления N на K, и первые M процессов получают на один элемент
больше, где M - остаток от деления N на K. Таким образом, вектор делится процессами на примерно равные части,
каждая из которых локально обрабатывается своим процессом, что обеспечивает максимальную эффективность алгоритма.
Когда локальная обработка процессами завершена, результат пересылается на нулевой процесс,
на котором вычисляется минимум из локальных минимумов. Затем осуществляется рассылка результата на другие процессы.

## Описание программной реализации параллельного алгоритма

Реализация выполнена на языке C++ с использованием библиотеки MPI.  

Основные этапы:

- Инициализация и валидация входных данных;  
- Определение диапазона элементов, обрабатываемых каждым процессом;  
- Локальное вычисление минимума;  
- Сбор частичных результатов между всеми процессами, нахождение и пересылка результата
на каждый процесс при помощи MPI-функции `MPI_Allreduce`;  
- Возврат итогового значения каждым процессом.

### Ключевые функции

- `MPI_Comm_rank`, `MPI_Comm_size` — определяют номер процесса и общее количество процессов;  
- `MPI_Allreduce` — собирает результаты со всех процессов и осуществляет над ними
итоговую операцию поиска минимума, рассылая итоговый результат на все процессы.  

### Валидация данных

Не допускается пустой вектор в качестве входных данных, поскольку в нём невозможно опеределить минимальный элемент.

## Результаты экспериментов

### Условия экспериментов

- Размеры векторов: \(10^7\) , \(5*10^7\) ,  \(10^9\) элементов.  
- Среда выполнения: Windows, MPI (4 процесса).  
- Измерение времени проводилось встроенными средствами тестового фреймворка GoogleTest.  

---

### Результаты при размере вектора \(10^7\)

| Режим выполнения | Число процессов | Время (сек) | Ускорение |  Эффективность, % |
|:-----------------|----------------:|------------:|:----------|-------------------|
| SEQ              | 1               | 9.15        | 1.00      |                   |
| MPI              | 2               | 9.1         | 1.01      | 25,2              |
| MPI              | 4               | 12.5        | 0.99      | 24,7              |
| MPI              | 8               | 24.9        | 0.99      | 12,3              |

**Вывод:** наибольшее ускорение достигается при 2 процессах, что не ожидалось, поскольку процессор имеет 4 ядра,
 возможно это связано с тем что при 2 процессах меньше накладные расходы на коммуникацию

---

### Результаты при размере вектора \(5*10^7\)

| Режим выполнения | Число процессов | Время (сек) | Ускорение |  Эффективность, % |
|:-----------------|----------------:|------------:|:----------|-------------------|
| SEQ              | 1               | 44.5        | 1.00      |                   |
| MPI              | 2               | 44.8        | 0.99      | 12,3              |
| MPI              | 4               | 60.6        | 1.01      | 25,2              |
| MPI              | 8               | 24.9        | 0.99      | 12,3              |

**Вывод:** как ожидалось, наибольшее ускорение достигается на 4 процессах для 4-ядерного процессора, ускорение малое

---

### Результаты при размере вектора \(10^9\)

| Режим выполнения | Число процессов | Время (сек) | Ускорение |  Эффективность, % |
|:-----------------|----------------:|------------:|:----------|-------------------|
| SEQ              | 1               | 91          | 1.00      |                   |
| MPI              | 2               | 98          | 0.92      | 11,6              |
| MPI              | 4               | 128         | 0.99      | 12,3              |

**Вывод:** на очень больших данных происходит замедление при использовании параллельной версии,
что не оправдало ожидания (ожидалось, что при больших данных распараллеливание будет эффективнее).
Возможно, это связано с ограниченностью кэшированной памяти, что усложняет распараллеливание на больших данных.

## Подтверждение корректности

Были выбраны функциональные тесты на следующих входных данных, предполагающие различные сценарии работы алгоритмов:

1. Малый вектор {3, 1, 4, 1, 5}
2. Вектор с единстенным минимальным элементом в середине {9, 2, 6, 1, 8, 3, 7}
3. Вектор со смешанными числами {5, 4, 3, 2, 1, 0, -1, -2}
4. Вектор с повторяющимися отрицательными значениями {-5, -55, -5, -3, -100000, -111111, -9, -111111}
5. Вектор из одного элемента {7}

Результаты последовательной и параллельной версий совпали со значением, возвращаемым стандартной функцией std::min_element,
следовательно, оба алгоритма работают корректно.

---

## Выводы

1. Реализованы последовательная (SEQ) и параллельная (MPI) версии алгоритма поиска минимального элемента в векторе.
2. Тестовая инфраструктура обеспечивает комплексную проверку корректности обеих реализаций алгоритма
с точки зрения функциональности и производительности при различных размерах тестовых данных.
3. Предполагалось, что параллельная MPI-реализация эффективно распределяет вычисления между процессами,
используя стратегию блочного распределения данных с учетом остатка для балансировки нагрузки.
Ожидания не оправдались, так как ускорение удалось получить небольшое и лишь при определённом размере входных данных
(больше млн и меньше млр элементов). Вероятно, это связано с накладными расходами на параллельные вычисленения
и некоторыми техническими особенностями реализации параллельного алгоритма.
Алгоритм может быть модернизирован для получения большего ускорения, так как в данный момент
использование параллельных вычислений не оправдывает затрат на его реализацию.

## Заключение

В ходе лабораторной работы был реализован и протестирован алгоритм нахождения минимума вектора
с использованием технологии MPI. Проведён сравнительный анализ с последовательной версией,
подтверждена корректность вычислений и измерено ускорение. Было так же показано, что MPI версия
при достаточно больших данных имеет ускорение по сравнению с версией SEQ.

## Список литературы

1. Документация по OpenMPI — <https://www.open-mpi.org/doc/>
2. cppreference.com - <https://en.cppreference.com/>
3. Лекции по параллельному программированию ННГУ

---
